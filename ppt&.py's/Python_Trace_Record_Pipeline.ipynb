{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b40283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to Trace a Record Through a Pipeline\n",
    "# ----------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# 1Ô∏è‚É£ Setup logging\n",
    "logging.basicConfig(\n",
    "    filename=\"trace_record.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "print(\"üöÄ Pipeline trace started...\")\n",
    "logging.info(\"Trace started\")\n",
    "\n",
    "# 2Ô∏è‚É£ Create sample data (Raw Layer)\n",
    "raw_data = [\n",
    "    {\"shipment_id\": \"SHIP123\", \"origin\": \"Chennai\", \"destination\": \"Delhi\", \"weight\": 12.5, \"status\": \"Received\", \"timestamp\": \"2025-11-05 10:00\"},\n",
    "    {\"shipment_id\": \"SHIP124\", \"origin\": \"Hyderabad\", \"destination\": \"Bangalore\", \"weight\": 8.0, \"status\": \"Received\", \"timestamp\": \"2025-11-05 10:05\"}\n",
    "]\n",
    "raw_df = pd.DataFrame(raw_data)\n",
    "print(\"\\n‚úÖ Step 1: Raw Data\")\n",
    "print(raw_df)\n",
    "logging.info(f\"Step 1: Loaded {len(raw_df)} records\")\n",
    "\n",
    "# 3Ô∏è‚É£ Pick a record to trace\n",
    "record_id = \"SHIP123\"\n",
    "trace_df = raw_df[raw_df[\"shipment_id\"] == record_id]\n",
    "print(f\"\\nüîç Tracing record: {record_id}\")\n",
    "print(trace_df)\n",
    "logging.info(f\"Tracing record {record_id} from raw data\")\n",
    "\n",
    "# 4Ô∏è‚É£ Step 2: Clean the data\n",
    "cleaned_df = raw_df.copy()\n",
    "cleaned_df[\"status\"] = cleaned_df[\"status\"].replace(\"Received\", \"Validated\")\n",
    "print(\"\\n‚úÖ Step 2: Cleaned Data\")\n",
    "print(cleaned_df[cleaned_df[\"shipment_id\"] == record_id])\n",
    "logging.info(f\"Record {record_id} cleaned successfully\")\n",
    "\n",
    "# 5Ô∏è‚É£ Step 3: Transformation (Add Delivery Time)\n",
    "cleaned_df[\"delivery_time_hr\"] = [5, 2]\n",
    "print(\"\\n‚úÖ Step 3: Transformed Data\")\n",
    "print(cleaned_df[cleaned_df[\"shipment_id\"] == record_id])\n",
    "logging.info(f\"Record {record_id} transformed successfully\")\n",
    "\n",
    "# 6Ô∏è‚É£ Step 4: Aggregation (Group by Destination)\n",
    "agg_df = cleaned_df.groupby(\"destination\").agg(\n",
    "    total_shipments=(\"shipment_id\", \"count\"),\n",
    "    avg_weight=(\"weight\", \"mean\")\n",
    ").reset_index()\n",
    "print(\"\\n‚úÖ Step 4: Aggregated Data\")\n",
    "print(agg_df)\n",
    "logging.info(\"Aggregation completed\")\n",
    "\n",
    "# 7Ô∏è‚É£ Step 5: Verify trace after aggregation\n",
    "if record_id in list(cleaned_df[\"shipment_id\"]):\n",
    "    print(f\"\\nüîÅ Record {record_id} found throughout all pipeline stages.\")\n",
    "    logging.info(f\"Record {record_id} verified successfully across stages.\")\n",
    "else:\n",
    "    print(f\"‚ùå Record {record_id} missing after transformation!\")\n",
    "    logging.error(f\"Record {record_id} missing in output.\")\n",
    "\n",
    "# 8Ô∏è‚É£ Completion\n",
    "print(\"\\nüéâ Record trace completed successfully!\")\n",
    "logging.info(\"Record trace completed\")\n",
    "\n",
    "# 9Ô∏è‚É£ Summary\n",
    "\"\"\"\n",
    "- This simulates tracing one record through multiple ETL steps.\n",
    "- Helps debug issues like data loss or wrong transformations.\n",
    "- Use filters + logging for every stage in production pipelines.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
