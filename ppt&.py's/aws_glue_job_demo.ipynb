{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4750b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Topic: AWS Glue Jobs (Cataloging & Light Transformations)\n",
    "=========================================================\n",
    "Simulates an AWS Glue ETL job performing light transformations\n",
    "and writing processed data back to S3.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 1 ‚Äì Initialize Spark Session (for Glue)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"üöÄ Starting Glue ETL Job...\")\n",
    "spark = SparkSession.builder.appName(\"Glue_Transformations_Demo\").getOrCreate()\n",
    "logger = logging.getLogger(\"glue_demo\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 2 ‚Äì Read Data from Raw Zone\n",
    "# -------------------------------------------------------------------\n",
    "raw_path = \"s3://supplychain-data-demo/raw/shipments/\"\n",
    "logger.info(f\"üì• Reading data from: {raw_path}\")\n",
    "df_raw = spark.read.json(raw_path)\n",
    "\n",
    "logger.info(\"‚úÖ Sample schema:\")\n",
    "df_raw.printSchema()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 3 ‚Äì Light Transformations\n",
    "# -------------------------------------------------------------------\n",
    "logger.info(\"‚öôÔ∏è Performing data cleaning and transformations...\")\n",
    "\n",
    "df_cleaned = (\n",
    "    df_raw\n",
    "    .filter(col(\"shipment_id\").isNotNull())\n",
    "    .withColumnRenamed(\"ShipmentID\", \"shipment_id\")\n",
    "    .withColumnRenamed(\"Weight\", \"weight\")\n",
    "    .withColumnRenamed(\"Status\", \"status\")\n",
    "    .filter(col(\"status\") != \"Cancelled\")\n",
    ")\n",
    "\n",
    "logger.info(f\"‚úÖ Cleaned record count: {df_cleaned.count()}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 4 ‚Äì Write to Trusted Zone\n",
    "# -------------------------------------------------------------------\n",
    "trusted_path = \"s3://supplychain-data-demo/trusted/shipments/\"\n",
    "logger.info(f\"üì§ Writing cleaned data to: {trusted_path}\")\n",
    "(\n",
    "    df_cleaned\n",
    "    .repartition(1)\n",
    "    .write.mode(\"overwrite\")\n",
    "    .parquet(trusted_path)\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ Data successfully written to Trusted Zone.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 5 ‚Äì Update Glue Data Catalog (Simulation)\n",
    "# -------------------------------------------------------------------\n",
    "glue = boto3.client(\"glue\")\n",
    "table_name = \"shipments_trusted\"\n",
    "database_name = \"supplychain_catalog\"\n",
    "\n",
    "try:\n",
    "    logger.info(\"üóÇÔ∏è Registering table in Glue Data Catalog...\")\n",
    "    glue.create_table(\n",
    "        DatabaseName=database_name,\n",
    "        TableInput={\n",
    "            \"Name\": table_name,\n",
    "            \"StorageDescriptor\": {\n",
    "                \"Columns\": [\n",
    "                    {\"Name\": \"shipment_id\", \"Type\": \"string\"},\n",
    "                    {\"Name\": \"weight\", \"Type\": \"double\"},\n",
    "                    {\"Name\": \"status\", \"Type\": \"string\"},\n",
    "                ],\n",
    "                \"Location\": trusted_path,\n",
    "                \"InputFormat\": \"org.apache.hadoop.mapred.TextInputFormat\",\n",
    "                \"OutputFormat\": \"org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    logger.info(f\"‚úÖ Table '{table_name}' registered in Glue Catalog.\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping catalog registration (may already exist): {e}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 6 ‚Äì Stop Spark Session\n",
    "# -------------------------------------------------------------------\n",
    "spark.stop()\n",
    "logger.info(\"üèÅ Glue job completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
